{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# use gpu if cuda is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- __tuple__ - static list\n",
    "- __deterministic__ - no randomness in future states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', \n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition\"\"\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(448, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input extraction\n",
    "Extract and process rendered images from the envirionment. Uses __```torchvision```__ pakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3-4.4.0/lib/python3.5/site-packages/torchvision-0.2.0-py3.5.egg/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADWCAYAAADBwHkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ff8ed2f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reisze = T.Compose([T.ToPILImage(),\n",
    "                   T.Scale(40, interpolation=Image.CUBIC),\n",
    "                   T.ToTensor()])\n",
    "\n",
    "# This is based on the code from gym. Or so they said.\n",
    "screen_width = 600\n",
    "\n",
    "def get_cart_location():\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0) # MIDDLE of CART\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render(mode='rgb_array').transpose(\n",
    "        (2, 0, 1)) # transpose into torch order (CHW)?\n",
    "    # Strip off the top and bottom of the screen\n",
    "    screen = screen[:, 160:320]\n",
    "    view_width = 320\n",
    "    cart_location = get_cart_location()\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                           cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we hav ea square image centered on a cart\n",
    "    screen = screen[:,:,slice_range]\n",
    "    # convert to float, rescare, convert to torch tensor\n",
    "    # (this doesn't require a copy? lol)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    #Resize, add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).type(Tensor)\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1,2,0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "#### Hyperparameters and utilities\n",
    "Instantiates the defined model and its optimizer, and defines some utilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "\n",
    "model = DQN()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        return model(\n",
    "            Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1,1)\n",
    "    else:\n",
    "        return LongTensor([[random.randrange(2)]])\n",
    "    \n",
    "episode_durations = []\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.FloatTensor(episode_durations)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episodes averages and plot them too lol\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zersos(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "        \n",
    "    plt.pause(0.001) # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
